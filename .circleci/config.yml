version: 2.1


jobs:
  build:
    docker:
      - image: circleci/python:3.7
    steps:
      - checkout
      - restore_cache:
          key: v1-dependency-cache-{{ checksum "setup.py" }}-{{ checksum "Makefile" }}
      - run:
          name: install python dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make dev
      - save_cache:
          key: v1-dependency-cache-{{ checksum "setup.py" }}-{{ checksum "Makefile" }}
          paths:
            - "venv"
      - run:
          name: run tests
          command: |
            . venv/bin/activate
            make test
      - setup_remote_docker:
          version: 19.03.13
      - run:
          name: deploy docker images
          command: |
            docker build . -t seqtolang
            sleep 90
            mkdir -p workspace
            docker run --env "SEQTOLANG_TEXT=$(jq .review_text sample_0.json)" --rm seqtolang >> workspace/resulte.txt
            cat workspace/resulte.txt
            pwd
            ls
            ls workspace
      - persist_to_workspace:
          root: workspace
          paths:
            - resulte.txt

  build-translate:
    docker:
      - image: circleci/python:3.7
    steps:
      - attach_workspace:
          at: workspace
      - run:
          name: setup environment for translate
          command: |
            pip install torch torchvision torchaudio
            pip install transformers
      - run:
          name: write a traslation code 
          command: |
            echo "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
            model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")
            tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")
            inputs = tokenizer( \"translate English to German: Hugging Face is a technology company based in New York and Paris\", return_tensors=\"pt\" )
            outputs = model.generate(inputs[\"input_ids\"], max_length=40, num_beams=4, early_stopping=True)
            print(tokenizer.decode(outputs[0]))" > py.py
      - run:
          name: run 
          command: |
            python py.py
            ls
            pwd
            ls workspace



workflows:
  build_and_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/ 
      - build-translate:
          requires:
            - build